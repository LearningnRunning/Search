"""
ìŒì‹ì  ê²€ìƒ‰ ì—”ì§„
"""

from typing import Any, Optional

import pandas as pd
import torch
from sentence_transformers import SentenceTransformer, util

from .utils import jamo_similarity, normalize
from .embedding_loader import EmbeddingLoader, load_embeddings


class SemanticSearcher:
    """ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ì„ ìœ„í•œ í´ëž˜ìŠ¤"""

    def __init__(self, model_name: str = "snunlp/KR-SBERT-V40K-klueNLI-augSTS"):
        """
        Args:
            model_name: ì‚¬ìš©í•  SBERT ëª¨ë¸ëª…
        """
        self.model = SentenceTransformer(model_name)

    def similarity(
        self, query: str, candidates: list[str], top_k: int = 5
    ) -> list[tuple[str, float]]:
        """
        ì¿¼ë¦¬ì™€ í›„ë³´ë“¤ ê°„ì˜ ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            candidates: í›„ë³´ ë¬¸ìžì—´ë“¤
            top_k: ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ìˆ˜

        Returns:
            (í›„ë³´, ì ìˆ˜) íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸
        """
        query_embedding = self.model.encode(query, convert_to_tensor=True)
        candidate_embeddings = self.model.encode(candidates, convert_to_tensor=True)
        cos_scores = util.cos_sim(query_embedding, candidate_embeddings)[0]
        top_results = torch.topk(cos_scores, k=top_k)
        return [
            (candidates[idx], round(score.item(), 4))
            for idx, score in zip(top_results.indices, top_results.values, strict=False)
        ]


class DinerSearchEngine:
    """ìŒì‹ì  ê²€ìƒ‰ ì—”ì§„"""

    def __init__(
        self,
        diner_infos: Optional[list[dict[str, Any]]] = None,
        model_name: str = "snunlp/KR-SBERT-V40K-klueNLI-augSTS",
        embeddings_dir: str = "data/embeddings",
        use_precomputed_embeddings: bool = True
    ):
        """
        Args:
            diner_infos: ìŒì‹ì  ì •ë³´ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ë²¡í„° íŒŒì¼ì—ì„œ ë¡œë“œ)
            model_name: SBERT ëª¨ë¸ëª…
            embeddings_dir: ë²¡í„° íŒŒì¼ë“¤ì´ ì €ìž¥ëœ ë””ë ‰í† ë¦¬
            use_precomputed_embeddings: ë¯¸ë¦¬ ê³„ì‚°ëœ ë²¡í„°ë¥¼ ì‚¬ìš©í• ì§€ ì—¬ë¶€
        """
        self.model_name = model_name
        self.embeddings_dir = embeddings_dir
        self.use_precomputed_embeddings = use_precomputed_embeddings
        
        # ë²¡í„° ë¡œë” ì´ˆê¸°í™”
        self.embedding_loader = None
        self.diner_embeddings = None
        
        if diner_infos is not None:
            self.diner_infos = diner_infos
        else:
            self.diner_infos = None
        
        # ë¯¸ë¦¬ ê³„ì‚°ëœ ë²¡í„° ì‚¬ìš© ì‹œë„
        if use_precomputed_embeddings:
            self._load_precomputed_embeddings()
        
        # ë²¡í„° ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
        if self.diner_embeddings is None:
            self._initialize_with_model()
    
    def _load_precomputed_embeddings(self):
        """ë¯¸ë¦¬ ê³„ì‚°ëœ ë²¡í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            print("ðŸ”„ ë¯¸ë¦¬ ê³„ì‚°ëœ ë²¡í„° ë¡œë“œ ì¤‘...")
            self.embedding_loader = load_embeddings(self.embeddings_dir)
            
            if self.embedding_loader and self.embedding_loader.is_loaded():
                self.diner_embeddings = self.embedding_loader.get_embeddings()
                if self.diner_infos is None:
                    self.diner_infos = self.embedding_loader.get_diner_infos()
                
                info = self.embedding_loader.get_info()
                print(f"âœ… ë¯¸ë¦¬ ê³„ì‚°ëœ ë²¡í„° ë¡œë“œ ì™„ë£Œ!")
                print(f"   ìŒì‹ì  ìˆ˜: {info['num_diners']:,}ê°œ")
                print(f"   ë²¡í„° ì°¨ì›: {info['embedding_dim']}")
                print(f"   íŒŒì¼ í¬ê¸°: {info['file_size_mb']:.1f}MB")
                print(f"   ëª¨ë¸: {info['model_name']}")
            else:
                print("âš ï¸ ë¯¸ë¦¬ ê³„ì‚°ëœ ë²¡í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"âŒ ë²¡í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print("ðŸ”„ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")
    
    def _initialize_with_model(self):
        """ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë²¡í„°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        print("ðŸ¤– SBERT ëª¨ë¸ ë¡œë“œ ì¤‘...")
        self.semantic_searcher = SemanticSearcher(self.model_name)
        
        if self.diner_infos is None:
            from .utils import load_diner_data
            self.diner_infos = load_diner_data()
        
        # ìŒì‹ì  ì´ë¦„ë“¤ì˜ ìž„ë² ë”©ì„ ë¯¸ë¦¬ ê³„ì‚°
        diner_names = [d["name"] for d in self.diner_infos]
        print(f"ðŸ”¢ {len(diner_names)}ê°œ ìŒì‹ì ì˜ ë²¡í„° ìƒì„± ì¤‘...")
        self.diner_embeddings = self.semantic_searcher.model.encode(
            diner_names, convert_to_tensor=True
        )
        print("âœ… ë²¡í„° ìƒì„± ì™„ë£Œ!")

    def search(
        self, query: str, top_k: int = 5, jamo_threshold: float = 0.7
    ) -> pd.DataFrame:
        """
        ìŒì‹ì ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ìˆ˜
            jamo_threshold: ìžëª¨ ìœ ì‚¬ë„ ìž„ê³„ê°’

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ DataFrame
        """
        norm_query = normalize(query)

        # 1. ì •í™•í•œ ë§¤ì¹­
        exact_matches = [
            d for d in self.diner_infos if normalize(d["name"]) == norm_query
        ]
        if exact_matches:
            return pd.DataFrame(exact_matches).assign(match_type="ì •í™•í•œ ë§¤ì¹­")

        # 2. ë¶€ë¶„ ë§¤ì¹­
        partial_matches = [
            d for d in self.diner_infos if norm_query in normalize(d["name"])
        ]
        if partial_matches:
            return pd.DataFrame(partial_matches).assign(match_type="ë¶€ë¶„ ë§¤ì¹­")

        # 3. ìžëª¨ ê¸°ë°˜ ì§ì ‘ ë§¤ì¹­
        for d in self.diner_infos:
            is_jamo, score = jamo_similarity(norm_query, normalize(d["name"]))
            if is_jamo:
                return pd.DataFrame(
                    [
                        {
                            "name": d["name"],
                            "idx": d["idx"],
                            "jamo_score": score,
                            "match_type": "ìžëª¨ ë§¤ì¹­",
                        }
                    ]
                )

        # 4. ìžëª¨ ìœ ì‚¬ë„ ì „ì²´ ê³„ì‚°
        jamo_scores = []
        for d in self.diner_infos:
            _, score = jamo_similarity(norm_query, normalize(d["name"]))
            jamo_scores.append((d, score))

        jamo_top = sorted(
            [x for x in jamo_scores if x[1] >= jamo_threshold],
            key=lambda x: x[1],
            reverse=True,
        )[:top_k]

        # 5. SBERT ì˜ë¯¸ë¡ ì  ê²€ìƒ‰
        if self.embedding_loader:
            # ë¯¸ë¦¬ ê³„ì‚°ëœ ë²¡í„° ì‚¬ìš©
            query_emb = self.semantic_searcher.model.encode(query, convert_to_tensor=True)
        else:
            # ê¸°ì¡´ ë°©ì‹
            query_emb = self.semantic_searcher.model.encode(query, convert_to_tensor=True)
        
        cos_scores = util.cos_sim(query_emb, self.diner_embeddings)[0]
        topk = torch.topk(cos_scores, k=top_k)
        sbert_top = [
            (self.diner_infos[idx], round(score.item(), 4))
            for idx, score in zip(topk.indices.cpu(), topk.values.cpu(), strict=False)
        ]

        # 6. ì ìˆ˜ í•©ì‚° (í†µí•© ê²€ìƒ‰)
        combined = {}
        for d, score in jamo_top:
            key = d["name"]
            combined[key] = {"name": key, "idx": d["idx"], "score": score * 0.5}

        for d, score in sbert_top:
            key = d["name"]
            if key in combined:
                combined[key]["score"] += score * 0.5
            else:
                combined[key] = {"name": key, "idx": d["idx"], "score": score * 0.5}

        return pd.DataFrame(
            sorted(combined.values(), key=lambda x: x["score"], reverse=True)[:top_k]
        ).assign(match_type="í†µí•© ê²€ìƒ‰")
    
    def get_info(self) -> dict:
        """ê²€ìƒ‰ ì—”ì§„ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        info = {
            "model_name": self.model_name,
            "num_diners": len(self.diner_infos),
            "use_precomputed_embeddings": self.use_precomputed_embeddings
        }
        
        if self.embedding_loader:
            info.update(self.embedding_loader.get_info())
        
        return info
