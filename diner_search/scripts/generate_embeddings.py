"""
ìŒì‹ì  ì´ë¦„ ë²¡í„° ìƒì„± ë° ì €ì¥ ìŠ¤í¬ë¦½íŠ¸
"""

import json
import os
import sys
import torch
from pathlib import Path
from sentence_transformers import SentenceTransformer
from tqdm import tqdm

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from src.utils import load_diner_data


def generate_and_save_embeddings(
    model_name: str = "snunlp/KR-SBERT-V40K-klueNLI-augSTS",
    output_dir: str = "data/embeddings",
    batch_size: int = 32
):
    """
    ìŒì‹ì  ì´ë¦„ì˜ ë²¡í„°ë¥¼ ìƒì„±í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        model_name: ì‚¬ìš©í•  SBERT ëª¨ë¸ëª…
        output_dir: ë²¡í„° ì €ì¥ ë””ë ‰í† ë¦¬
        batch_size: ë°°ì¹˜ í¬ê¸°
    """
    print(f"ğŸš€ ìŒì‹ì  ì´ë¦„ ë²¡í„° ìƒì„± ì‹œì‘...")
    print(f"ğŸ“¦ ëª¨ë¸: {model_name}")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_dir}")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    # ë°ì´í„° ë¡œë“œ
    print("ğŸ“Š ìŒì‹ì  ë°ì´í„° ë¡œë“œ ì¤‘...")
    diner_infos = load_diner_data()
    print(f"âœ… {len(diner_infos)}ê°œì˜ ìŒì‹ì  ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    
    # ëª¨ë¸ ë¡œë“œ
    print("ğŸ¤– SBERT ëª¨ë¸ ë¡œë“œ ì¤‘...")
    model = SentenceTransformer(model_name)
    print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    # ìŒì‹ì  ì´ë¦„ ì¶”ì¶œ
    diner_names = [d["name"] for d in diner_infos]
    
    # ë²¡í„° ìƒì„±
    print("ğŸ”¢ ë²¡í„° ìƒì„± ì¤‘...")
    embeddings = []
    
    for i in tqdm(range(0, len(diner_names), batch_size), desc="ë²¡í„° ìƒì„±"):
        batch_names = diner_names[i:i + batch_size]
        batch_embeddings = model.encode(batch_names, convert_to_tensor=True)
        embeddings.append(batch_embeddings.cpu())
    
    # ëª¨ë“  ë°°ì¹˜ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
    all_embeddings = torch.cat(embeddings, dim=0)
    print(f"âœ… ë²¡í„° ìƒì„± ì™„ë£Œ: {all_embeddings.shape}")
    
    # ë©”íƒ€ë°ì´í„° ì¤€ë¹„
    metadata = {
        "model_name": model_name,
        "num_diners": len(diner_infos),
        "embedding_dim": all_embeddings.shape[1],
        "diner_names": diner_names,
        "diner_infos": diner_infos
    }
    
    # íŒŒì¼ ì €ì¥
    print("ğŸ’¾ íŒŒì¼ ì €ì¥ ì¤‘...")
    
    # PyTorch í…ì„œë¡œ ì €ì¥ (.pt)
    torch.save(all_embeddings, os.path.join(output_dir, "diner_embeddings.pt"))
    print("âœ… diner_embeddings.pt ì €ì¥ ì™„ë£Œ")
    
    # ë©”íƒ€ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ì €ì¥
    with open(os.path.join(output_dir, "diner_metadata.json"), "w", encoding="utf-8") as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    print("âœ… diner_metadata.json ì €ì¥ ì™„ë£Œ")
    
    # ì••ì¶•ëœ í˜•íƒœë¡œë„ ì €ì¥ (.pkl)
    import pickle
    compressed_data = {
        "embeddings": all_embeddings,
        "metadata": metadata
    }
    with open(os.path.join(output_dir, "diner_embeddings.pkl"), "wb") as f:
        pickle.dump(compressed_data, f)
    print("âœ… diner_embeddings.pkl ì €ì¥ ì™„ë£Œ")
    
    print(f"ğŸ‰ ëª¨ë“  íŒŒì¼ ì €ì¥ ì™„ë£Œ!")
    print(f"ğŸ“Š ë²¡í„° í¬ê¸°: {all_embeddings.shape}")
    print(f"ğŸ’¾ ì €ì¥ëœ íŒŒì¼:")
    print(f"   - {output_dir}/diner_embeddings.pt")
    print(f"   - {output_dir}/diner_metadata.json")
    print(f"   - {output_dir}/diner_embeddings.pkl")


def verify_embeddings(embeddings_dir: str = "data/embeddings"):
    """
    ìƒì„±ëœ ë²¡í„° íŒŒì¼ë“¤ì„ ê²€ì¦í•©ë‹ˆë‹¤.
    
    Args:
        embeddings_dir: ë²¡í„° íŒŒì¼ë“¤ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬
    """
    print("ğŸ” ë²¡í„° íŒŒì¼ ê²€ì¦ ì¤‘...")
    
    # .pt íŒŒì¼ ê²€ì¦
    pt_path = os.path.join(embeddings_dir, "diner_embeddings.pt")
    if os.path.exists(pt_path):
        embeddings = torch.load(pt_path)
        print(f"âœ… diner_embeddings.pt: {embeddings.shape}")
    else:
        print("âŒ diner_embeddings.pt íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # .pkl íŒŒì¼ ê²€ì¦
    pkl_path = os.path.join(embeddings_dir, "diner_embeddings.pkl")
    if os.path.exists(pkl_path):
        import pickle
        with open(pkl_path, "rb") as f:
            data = pickle.load(f)
        print(f"âœ… diner_embeddings.pkl: {data['embeddings'].shape}")
        print(f"   ë©”íƒ€ë°ì´í„°: {len(data['metadata']['diner_names'])}ê°œ ìŒì‹ì ")
    else:
        print("âŒ diner_embeddings.pkl íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # JSON ë©”íƒ€ë°ì´í„° ê²€ì¦
    json_path = os.path.join(embeddings_dir, "diner_metadata.json")
    if os.path.exists(json_path):
        with open(json_path, "r", encoding="utf-8") as f:
            metadata = json.load(f)
        print(f"âœ… diner_metadata.json: {metadata['num_diners']}ê°œ ìŒì‹ì ")
        print(f"   ëª¨ë¸: {metadata['model_name']}")
        print(f"   ë²¡í„° ì°¨ì›: {metadata['embedding_dim']}")
    else:
        print("âŒ diner_metadata.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ìŒì‹ì  ì´ë¦„ ë²¡í„° ìƒì„±")
    parser.add_argument("--model", default="snunlp/KR-SBERT-V40K-klueNLI-augSTS", 
                       help="ì‚¬ìš©í•  SBERT ëª¨ë¸ëª…")
    parser.add_argument("--output-dir", default="data/embeddings", 
                       help="ë²¡í„° ì €ì¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--batch-size", type=int, default=32, 
                       help="ë°°ì¹˜ í¬ê¸°")
    parser.add_argument("--verify", action="store_true", 
                       help="ê¸°ì¡´ ë²¡í„° íŒŒì¼ ê²€ì¦")
    
    args = parser.parse_args()
    
    if args.verify:
        verify_embeddings(args.output_dir)
    else:
        generate_and_save_embeddings(
            model_name=args.model,
            output_dir=args.output_dir,
            batch_size=args.batch_size
        ) 